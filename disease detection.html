<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Crop Disease Detector</title>
    <!-- Load Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        /* Custom styles for mobile-first design and modern look */
        body { font-family: 'Inter', sans-serif; background-color: #f0fdf4; }
        #videoElement {
            transform: scaleX(-1); /* Mirror the video stream for selfie-like view */
            width: 100%;
            max-width: 600px;
            height: auto;
            border-radius: 1.5rem; /* Large rounded corners */
            box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
            background-color: #000;
        }
        #captureCanvas { display: none; } /* Canvas is only for processing */
        .card {
            background-color: white;
            padding: 1.5rem;
            border-radius: 1rem;
            box-shadow: 0 1px 3px 0 rgba(0, 0, 0, 0.1), 0 1px 2px 0 rgba(0, 0, 0, 0.06);
            margin-bottom: 1.5rem;
        }
        .pulse-animation {
            animation: pulse 2s cubic-bezier(0.4, 0, 0.6, 1) infinite;
        }
        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: .5; }
        }
    </style>
</head>
<body class="p-4 sm:p-8 min-h-screen flex flex-col items-center">

    <header class="text-center mb-6">
        <h1 class="text-3xl font-bold text-green-700">DICE-Crop Disease Detection-AI</h1>
        <p class="text-gray-600">Real-time Crop Health Assistant</p>
    </header>

    <main class="w-full max-w-xl">
        <!-- 1. Camera Feed Area -->
        <div class="card">
            <h2 class="text-xl font-semibold mb-3 text-green-800">1. Capture Image</h2>
            <video id="videoElement" autoplay playsinline></video>
            <canvas id="captureCanvas"></canvas>
            <button id="captureBtn" class="w-full mt-4 py-3 bg-green-500 text-white font-bold rounded-full hover:bg-green-600 transition duration-300 shadow-md">
                Capture for Analysis
            </button>
            <div id="cameraStatus" class="mt-2 text-center text-red-500 font-medium hidden">Camera not available or access denied.</div>
        </div>

        <!-- 2. Result Area -->
        <div class="card">
            <h2 class="text-xl font-semibold mb-3 text-green-800">2. Detection Result</h2>

            <div id="loadingIndicator" class="hidden text-center py-8">
                <div class="w-8 h-8 border-4 border-green-500 border-t-transparent rounded-full mx-auto mb-2 pulse-animation"></div>
                <p class="text-gray-600">Analyzing crop... please wait.</p>
            </div>

            <div id="resultsContent" class="hidden">
                <h3 class="text-lg font-bold text-gray-800 mb-2">Analysis:</h3>
                <p id="analysisText" class="text-gray-700 whitespace-pre-wrap"></p>
                <div id="citationContainer" class="mt-4 border-t pt-3 hidden">
                    <h4 class="text-sm font-semibold text-gray-600 mb-1">Sources Grounding:</h4>
                    <ul id="sourcesList" class="text-xs text-gray-500 list-disc pl-5 space-y-1"></ul>
                </div>
            </div>
        </div>

        <!-- Hidden Alert Box -->
        <div id="alertBox" class="fixed inset-0 bg-black bg-opacity-50 hidden items-center justify-center p-4 z-50">
            <div class="bg-white rounded-xl p-6 max-w-sm w-full shadow-2xl">
                <h3 class="text-xl font-bold text-red-600 mb-3">Error</h3>
                <p id="alertMessage" class="text-gray-700 mb-4"></p>
                <button onclick="document.getElementById('alertBox').classList.add('hidden')" class="w-full py-2 bg-red-500 text-white rounded-lg hover:bg-red-600">Close</button>
            </div>
        </div>

    </main>

    <script>
        // Global variables provided by the environment
        const apiKey = ""; // API Key is automatically supplied by the canvas environment
        const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent?key=${apiKey}`;

        // DOM Elements
        const video = document.getElementById('videoElement');
        const canvas = document.getElementById('captureCanvas');
        const captureBtn = document.getElementById('captureBtn');
        const loadingIndicator = document.getElementById('loadingIndicator');
        const resultsContent = document.getElementById('resultsContent');
        const analysisText = document.getElementById('analysisText');
        const cameraStatus = document.getElementById('cameraStatus');
        const sourcesList = document.getElementById('sourcesList');
        const citationContainer = document.getElementById('citationContainer');

        let stream = null;

        /**
         * Converts ArrayBuffer (from Base64 decode) to a Base64 string.
         * @param {string} base64 - Base64 string to convert.
         * @returns {ArrayBuffer}
         */
        function base64ToArrayBuffer(base64) {
            const binary_string = window.atob(base64);
            const len = binary_string.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) {
                bytes[i] = binary_string.charCodeAt(i);
            }
            return bytes.buffer;
        }

        /**
         * Shows a custom modal alert box instead of window.alert()
         * @param {string} message - The message to display.
         */
        function showAlert(message) {
            document.getElementById('alertMessage').textContent = message;
            document.getElementById('alertBox').classList.remove('hidden');
            document.getElementById('alertBox').classList.add('flex');
        }

        /**
         * Initializes camera stream.
         */
        async function setupCamera() {
            try {
                // Request camera access, preferring the environment-facing (back) camera on mobile
                stream = await navigator.mediaDevices.getUserMedia({
                    video: {
                        facingMode: 'environment',
                        width: { ideal: 1280 },
                        height: { ideal: 720 }
                    }
                });
                video.srcObject = stream;
                video.onloadedmetadata = () => {
                    video.play();
                    cameraStatus.classList.add('hidden');
                    captureBtn.disabled = false;
                };
            } catch (error) {
                console.error("Error accessing camera: ", error);
                cameraStatus.textContent = "Error: Camera access denied or not found. Please ensure you grant permission.";
                cameraStatus.classList.remove('hidden');
                captureBtn.disabled = true;
            }
        }

        /**
         * Captures the current frame from the video stream, converts it to Base64, and triggers analysis.
         */
        function captureFrame() {
            if (!stream) {
                showAlert("Camera stream not active. Please ensure camera access is granted.");
                return;
            }

            // Set canvas dimensions to match video dimensions for a clear capture
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            const context = canvas.getContext('2d');

            // Draw the current video frame onto the canvas.
            // Note: We mirror the video for display, but draw it normally to the canvas
            // unless we want the captured image to be mirrored as well. For disease detection,
            // we usually want the non-mirrored (actual) view.
            context.drawImage(video, 0, 0, canvas.width, canvas.height);

            // Convert canvas content to Base64 (image/jpeg for smaller payload)
            const base64Image = canvas.toDataURL('image/jpeg', 0.8).split(',')[1];

            // Start analysis
            analyzeImage(base64Image);
        }

        /**
         * Calls the Gemini API to analyze the captured image.
         * @param {string} base64Data - Base64 encoded image data.
         */
        async function analyzeImage(base64Data) {
            loadingIndicator.classList.remove('hidden');
            resultsContent.classList.add('hidden');
            captureBtn.disabled = true;

            const userPrompt = "Analyze this image of a crop. Focus on detecting diseases common to **wheat and rice**. Based on visual evidence, what is the probable disease (if any)? Provide a brief, single-paragraph description of the symptoms and a preliminary, simple recommendation for a small farmer. Use Google Search to ground your findings for accuracy.";

            const payload = {
                contents: [{
                    parts: [
                        { text: userPrompt },
                        {
                            inlineData: {
                                mimeType: "image/jpeg",
                                data: base64Data
                            }
                        }
                    ]
                }],
                // Request Google Search grounding for real-time disease information
                tools: [{ "google_search": {} }],
                systemInstruction: {
                    parts: [{ text: "You are an expert agricultural pathologist assistant. Your goal is to provide fast, accurate, and actionable advice to farmers based on the image provided. Keep the tone helpful and professional. Your response MUST be concise." }]
                }
            };

            const maxRetries = 3;
            let currentRetry = 0;

            while (currentRetry < maxRetries) {
                try {
                    const response = await fetch(apiUrl, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify(payload)
                    });

                    if (!response.ok) {
                        throw new Error(`HTTP error! status: ${response.status}`);
                    }

                    const result = await response.json();
                    const candidate = result.candidates?.[0];

                    if (candidate && candidate.content?.parts?.[0]?.text) {
                        const text = candidate.content.parts[0].text;
                        analysisText.textContent = text;
                        
                        let sources = [];
                        sourcesList.innerHTML = '';
                        citationContainer.classList.add('hidden');

                        const groundingMetadata = candidate.groundingMetadata;
                        if (groundingMetadata && groundingMetadata.groundingAttributions) {
                            sources = groundingMetadata.groundingAttributions
                                .map(attribution => ({
                                    uri: attribution.web?.uri,
                                    title: attribution.web?.title,
                                }))
                                .filter(source => source.uri && source.title);

                            if (sources.length > 0) {
                                sources.forEach(source => {
                                    const listItem = document.createElement('li');
                                    const link = document.createElement('a');
                                    link.href = source.uri;
                                    link.target = "_blank";
                                    link.textContent = source.title;
                                    link.className = "text-blue-500 hover:text-blue-700 hover:underline";
                                    listItem.appendChild(link);
                                    sourcesList.appendChild(listItem);
                                });
                                citationContainer.classList.remove('hidden');
                            }
                        }
                    } else {
                        analysisText.textContent = "Detection failed: Could not get a response from the AI model.";
                    }

                    break; // Exit loop on success

                } catch (error) {
                    console.error(`Analysis attempt ${currentRetry + 1} failed: `, error);
                    currentRetry++;
                    if (currentRetry < maxRetries) {
                        // Exponential backoff wait (e.g., 1s, 2s, 4s)
                        await new Promise(resolve => setTimeout(resolve, Math.pow(2, currentRetry) * 1000));
                    } else {
                        analysisText.textContent = "AI Analysis failed after multiple retries. Please check your internet connection and try again.";
                        showAlert("AI Analysis failed. Please try again.");
                    }
                }
            }

            loadingIndicator.classList.add('hidden');
            resultsContent.classList.remove('hidden');
            captureBtn.disabled = false;
        }

        // --- Event Listeners and Initialization ---

        captureBtn.addEventListener('click', captureFrame);

        // Start camera setup when the page loads
        window.onload = setupCamera;

    </script>
</body>
</html>
